{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb4bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import models\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff342f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "new angle: 2.9163774645578546\n",
      "2.8970587316326757\n",
      "2.9356961974830336\n",
      "new angle: 2.5856427835937312\n",
      "2.5373006465617554\n",
      "2.6339849206257067\n",
      "new angle: 2.433949735487924\n",
      "2.4270437633774815\n",
      "2.440855707598366\n",
      "new angle: 2.3820110714676814\n",
      "2.3735952705787096\n",
      "2.3904268723566533\n",
      "new angle: 2.2682701460805754\n",
      "2.2420432660517715\n",
      "2.294497026109379\n",
      "new angle: 1.9448751063765348\n",
      "1.7376088927345095\n",
      "2.1521413200185604\n",
      "new angle: 1.5370115416091572\n",
      "1.4399161988362434\n",
      "1.6341068843820707\n",
      "new angle: 1.3664113002285538\n",
      "1.340374279578911\n",
      "1.3924483208781966\n",
      "new angle: 1.2117053352983471\n",
      "1.15768815165117\n",
      "1.2657225189455241\n",
      "new angle: 1.0711856909584214\n",
      "1.040933354544549\n",
      "1.1014380273722937\n",
      "new angle: 0.9788991335614887\n",
      "0.9565449063075524\n",
      "1.001253360815425\n",
      "new angle: 0.8865692599987511\n",
      "0.8719769391838349\n",
      "0.9011615808136675\n",
      "new angle: 0.7269500113429936\n",
      "0.7034663501010223\n",
      "0.7504336725849649\n",
      "new angle: 0.6848537209989911\n",
      "0.6824115104220483\n",
      "0.6872959315759339\n",
      "new angle: 0.5385795492396365\n",
      "0.5072036212291715\n",
      "0.5699554772501014\n",
      "new angle: 0.23982244283162854\n",
      "0.08259294289809004\n",
      "0.39705194276516703\n",
      "new angle: 2.751010124075793\n",
      "2.5856427835937312\n",
      "2.9163774645578546\n",
      "new angle: 2.4079804034778025\n",
      "2.3820110714676814\n",
      "2.433949735487924\n",
      "new angle: 2.106572626228555\n",
      "1.9448751063765348\n",
      "2.2682701460805754\n",
      "new angle: 1.4517114209188555\n",
      "1.3664113002285538\n",
      "1.5370115416091572\n",
      "new angle: 1.1414455131283843\n",
      "1.0711856909584214\n",
      "1.2117053352983471\n",
      "new angle: 0.9327341967801199\n",
      "0.8865692599987511\n",
      "0.9788991335614887\n",
      "new angle: 0.7059018661709924\n",
      "0.6848537209989911\n",
      "0.7269500113429936\n",
      "new angle: 0.3892009960356325\n",
      "0.23982244283162854\n",
      "0.5385795492396365\n",
      "new angle: 2.579495263776798\n",
      "2.4079804034778025\n",
      "2.751010124075793\n",
      "new angle: 1.7791420235737054\n",
      "1.4517114209188555\n",
      "2.106572626228555\n",
      "new angle: 1.0370898549542522\n",
      "0.9327341967801199\n",
      "1.1414455131283843\n",
      "new angle: 0.5475514311033125\n",
      "0.3892009960356325\n",
      "0.7059018661709924\n",
      "new angle: 2.1793186436752516\n",
      "1.7791420235737054\n",
      "2.579495263776798\n",
      "new angle: 0.7923206430287824\n",
      "0.5475514311033125\n",
      "1.0370898549542522\n",
      "new angle: 1.485819643352017\n",
      "0.7923206430287824\n",
      "2.1793186436752516\n"
     ]
    }
   ],
   "source": [
    "### attempt at recreating the DT-14 dataset from the taxonomy paper \n",
    "def prune_leaf(graph):\n",
    "    ## graph is a directed graph\n",
    "    leaf_nodes = [node for node in graph.nodes() if graph.in_degree(node)!=0 and graph.out_degree(node)==0]\n",
    "    k=np.random.randint(0,len(leaf_nodes))\n",
    "    graph.remove_node(leaf_nodes[k])\n",
    "    return graph\n",
    "\n",
    "num_nodes=63   \n",
    "## pick random angles\n",
    "num_vecs=32\n",
    "angles=np.random.rand(num_vecs) * np.pi ## number of vectors with random values between 0 and pi, as y positive\n",
    "sorted_angles=np.sort(angles)\n",
    "\n",
    "G=nx.full_rary_tree(2, num_nodes,create_using=nx.DiGraph)\n",
    "## add the correct angles as data to nodes\n",
    "leaf_nodes = [node for node in G.nodes() if G.in_degree(node)!=0 and G.out_degree(node)==0]\n",
    "print(leaf_nodes)\n",
    "for i, angle in enumerate(sorted_angles): \n",
    "    G.nodes[leaf_nodes[i]][\"angle\"]=angle## put the generated angles on the leaves\n",
    "\n",
    "## for each level above the leaves do the parent calculation and add that angle.\n",
    "for i in range(num_vecs-2,-1,-1): ## backwards iteration through the layers\n",
    "    #vector=np.array([(1/2)*(np.cos(G.nodes[2*i+1][\"angle\"])+np.cos(G.nodes[2*i+2][\"angle\"])),(1/2)*(np.sin(G.nodes[2*i+1][\"angle\"])+np.sin(G.nodes[2*i+2][\"angle\"]))])\n",
    "    ### do we really need the vector? Just compute mean angle?\n",
    "    G.nodes[i][\"angle\"]=1/2*(G.nodes[2*i+1][\"angle\"]+G.nodes[2*i+2][\"angle\"])#np.arctan(vector[1]/vector[0]) ### what should this be?\n",
    "    print(\"new angle:\",G.nodes[i][\"angle\"])\n",
    "    print(G.nodes[2*i+1][\"angle\"])\n",
    "    print(G.nodes[2*i+2][\"angle\"])\n",
    "leaf_nodes = [node for node in G.nodes() if G.in_degree(node)!=0 and G.out_degree(node)==0]\n",
    "### prune the tree to be the correct number of leaf nodes\n",
    "while len(leaf_nodes)>=15:\n",
    "    prune_leaf(G)\n",
    "    leaf_nodes = [node for node in G.nodes() if G.in_degree(node)!=0 and G.out_degree(node)==0]\n",
    "# leaf_nodes = [node for node in G.nodes() if G.in_degree(node)!=0 and G.out_degree(node)==0]\n",
    "# print(leaf_nodes)\n",
    "# subax2= plt.subplot(121)\n",
    "# nx.draw(G)\n",
    "# print(G.nodes.data())    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886583d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the actual data from the structure    \n",
    "    \n",
    "def generate_data(G, num_data):\n",
    "# here we generate gaussian data around the generated structure for each of the leaves\n",
    "# positive and negative samples randomly generated\n",
    "    leaf_nodes = [node for node in G.nodes() if G.in_degree(node)!=0 and G.out_degree(node)==0]\n",
    "    data=[]\n",
    "    res=[]\n",
    "    labels=[]\n",
    "    for leaf in leaf_nodes:\n",
    "        # gen the data\n",
    "        theta=G.nodes[leaf][\"angle\"]\n",
    "        vector=np.array([(theta/np.pi)*np.cos(theta),(theta/np.pi)*np.sin(theta)])\n",
    "        for i in range(num_data):\n",
    "            if np.random.rand() >0.5:\n",
    "                data.append(np.random.multivariate_normal(vector, np.eye(2)))\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                data.append(np.random.multivariate_normal(-vector, np.eye(2)))\n",
    "                labels.append(0)\n",
    "        res.append(data)\n",
    "    return data, labels\n",
    "\n",
    "data,labels = generate_data(G,100)\n",
    "#print(np.sum(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a54ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 5.]\n",
      " [1. 0. 2. ... 0. 0. 6.]\n",
      " [1. 2. 0. ... 0. 0. 4.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 6. 4. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "### Generate the distance matrix A for the entire tree/graph\n",
    "A=dict(nx.all_pairs_dijkstra_path_length(G.to_undirected()))\n",
    "#print(A)\n",
    "num_nodes_postprune=60 ### how to do this well? We lose the index to node relationship if we remove all empty rows and columns... Maybe there is some way to retain it?\n",
    "mat=np.zeros((num_nodes_postprune,num_nodes_postprune)) ## only relevant for leaves (?)\n",
    "for key, value in A.items():\n",
    "    for key2,value2 in value.items():\n",
    "        mat[key][key2]=value2\n",
    "print(mat) \n",
    "\n",
    "\n",
    "# #### similarity matrix is not PD.  \n",
    "# Amax=mat.max()\n",
    "# tmp=mat/Amax\n",
    "# print(tmp)\n",
    "# S=np.ones((num_nodes_postprune,num_nodes_postprune))-tmp\n",
    "# print(S) \n",
    "\n",
    "# # remove all the rows and columns with ones\n",
    "# S_new=S[~np.all(S == 1, axis=1)]\n",
    "# S_new=S_new[:,~np.all(S_new == 1, axis=0)]\n",
    "# print(S_new.min())\n",
    "\n",
    "#C=np.linalg.cholesky(S_new) ## we cannot do this as we have 0's in the matrix\n",
    "#loop through the dictionaries and just fill in the values in the matrix\n",
    "#def generate_distance_matrix():\n",
    "    # takes graph and returns matrix which holds distances between nodes\n",
    "\n",
    "### maybe try S_ij= 1- A_ij/A_max\n",
    "# and have z be the cholesky decomposition of S and then learn with this\n",
    "# can we recreate y from X and z using some simple FCN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e680665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 16, 19, 20, 21, 22, 24, 35, 37, 48, 52, 53, 56, 59]\n",
      "[[-0.93940484  0.03541042]\n",
      " [-0.32006535  1.09701517]\n",
      " [ 0.85903057  0.83661454]\n",
      " ...\n",
      " [ 0.89112729  2.16843475]\n",
      " [-0.55875117  1.45407259]\n",
      " [ 0.33080101 -0.24379352]]\n"
     ]
    }
   ],
   "source": [
    "### train a model on a subset of datasets/domains and test on the rest\n",
    "\n",
    "### \n",
    "print(leaf_nodes)\n",
    "print(np.array(data))\n",
    "\n",
    "## create a matrix for just the leaf nodes and not the entire tree\n",
    "domain_A=np.zeros((14,14))\n",
    "for i,node1 in enumerate(leaf_nodes):\n",
    "    for j,node2 in enumerate(leaf_nodes):\n",
    "        domain_A[i][j]=mat[node1][node2]\n",
    "        \n",
    "indices=[0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "domain_index=[i*np.ones(100) for i in indices]\n",
    "#print(np.reshape(np.array(domain_index),-1)) The elements are float. May be an issue, or maybe not..\n",
    "source_data=np.array(data)[:399] # first 4 leaves/domains\n",
    "target_data=np.array(data)[400:]\n",
    "\n",
    "source_indices=domain_index[:399]\n",
    "target_indices=domain_index[400:]\n",
    "\n",
    "source_labels=labels[:399]\n",
    "target_labels=labels[400:]\n",
    "\n",
    "#model=models.BaseModel()\n",
    "\n",
    "\n",
    "## raw data encoder x_l->h_l\n",
    "\n",
    "## taxonomy encoder, A,u_l -> z_u_l\n",
    "\n",
    "## joint encoder, h_l,z_u_l -> e_l; final embedding\n",
    "\n",
    "# For fair comparison, all baselines and TSDA use the same encoder and predictor. \n",
    "# The encoder has the following components:\n",
    "# • A raw data encoder embeds the data xl into intermediate embeddings hl\n",
    "# • A taxonomy encoder embeds the domain distance matrix A and the domain index ul to the domain embeddings zul\n",
    "# with 1 fully connected (FC) layer. We use a taxonomy embedding loss Lg to pretrain the taxonomy encoder:\n",
    "# Lg = Eu1,u2∼p(u)# [lg(∥z⊤u1 zu2∥2, Au1,u2 )],\n",
    "# where u1, u2 are two independent domain identities sampled from p(u), and lg denotes a regression loss (e.g.,ℓ2\n",
    "# distance).\n",
    "# • A joint encoder then takes as input both hl and zl and produces the final embeddings el with 2 FC layers.\n",
    "# For toy datasets DT-14 and DT-40, we use 3 FC layers as the raw data encoder, \n",
    "# while for the real dataset ImageNet-AttributeDT and CUB-DT, \n",
    "# we use PyTorch’s default pretrained Resnet-18 as the raw data encoder.\n",
    "# All the predictors of baselines and TSDA contain 3 FC layers, and all the discriminators have 6 FC layers.\n",
    "# For GRDA, we treat every pair of domains that share a common grandparent node as connected, \n",
    "# construct GRDA’s domain graph, and feed it into its discriminator to recover the graph.\n",
    "# For the structure of the taxonomist, we first use a 6-FC-layer neural network T to produce\n",
    "# a 2-dimensional taxonomy representation tl of the data embedding el, \n",
    "# and then calculate the ℓ2 distance of a pair of taxonomy representations tl.\n",
    "\n",
    "\n",
    "# All the predictors of baselines and TSDA contain 3 FC layers, and all the discriminators have 6 FC layers. \n",
    "# For GRDA, we treat every pair of domains that share a common grandparent node as connected,\n",
    "# construct GRDA’s domain graph, and feed it into its discriminator to recover the graph.\n",
    "\n",
    "# For the structure of the taxonomist, we first use a 6-FC-layer neural network T\n",
    "# to produce a 2-dimensional taxonomy representation tl of the data embedding el \n",
    "# and then calculate the ℓ2 distance of a pair of taxonomy representations tl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53347b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make adjacency graph\n",
    "\n",
    "# A=np.zeros((63,63))\n",
    "# for i,_ in enumerate(A): incorrect, do it right!\n",
    "#     if i<=31:\n",
    "#        \n",
    "# print(A)\n",
    "# num_nodes=7\n",
    "#def make_graph(num_nodes, angle_all):\n",
    "# A = np.zeros((num_nodes, num_nodes))\n",
    "# for i in range(num_nodes//2):\n",
    "#         #for j in range(i + 1, num_nodes):\n",
    "#             #p = np.cos(angle_all[i]) * np.cos(angle_all[j]) + np.sin(angle_all[i]) * np.sin(angle_all[j])\n",
    "#             # for each node we should have that it has the desired connections, it is a binary tree!\n",
    "            \n",
    "#         ## both children, i.e. i has 2*i and 2*i+1 as children, add 1 for the index starting at 0\n",
    "#         A[i][(2*i)+1] = 1\n",
    "#         A[i][(2*i+1)+1] = 1\n",
    "#         A[(2*i+1)+1][i] = 1\n",
    "#         A[(2*i)+1][i] = 1\n",
    "    \n",
    "# print(A)\n",
    "\n",
    "\n",
    "# ## create the parents for each group of vectors\n",
    "# def make_parents(sorted_angles):\n",
    "#     a=sorted_angles[::2] \n",
    "#     parents=np.zeros((len(a),2))\n",
    "#     for i,angle in enumerate(a):\n",
    "#         ## create parent vector\n",
    "#         parents[i]=(1/2)*np.array([np.cos(sorted_angles[2*i])+np.cos(sorted_angles[2*i]),np.sin(sorted_angles[2*i])+np.sin(sorted_angles[2*i])])\n",
    "#     #print(parents)\n",
    "#     print(np.arctan(parents[:,0]/parents[:,1]))\n",
    "#     return np.arctan(parents[:,0]/parents[:,1]) #parents angles return\n",
    "\n",
    "# ## append the entire structure to an array, should we do this?\n",
    "# structure=[]\n",
    "# structure.append(sorted_angles)\n",
    "# k=2\n",
    "# tmp_angles=sorted_angles\n",
    "# while k!=1:\n",
    "#     parents=make_parents(tmp_angles)\n",
    "#     k=len(parents)\n",
    "    \n",
    "#     tmp_angles=parents\n",
    "#     print(tmp_angles)\n",
    "#     structure.append(parents)\n",
    "# print(structure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### network which takes in data, some additional structure data start with an index or similar\n",
    "\n",
    "### reconstruction loss of structure data\n",
    "\n",
    "## classification head\n",
    "\n",
    "## encoder/ discriminator a reasonable option for this?\n",
    "\n",
    "### maybe try S_ij= 1- A_ij\n",
    "# and have z be the cholesky decomposition of S and then learn with this\n",
    "# can we recreate y from X and z using some simple FCN?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
